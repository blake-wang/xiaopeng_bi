# 预发布环境配置
## 数据库配置
spark.local=false
jdbc.url=jdbc:mysql://10.46.120.165:3306/xiaopeng2_bi?user=denglh&password=deng123456&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false
jdbc.user=denglh
jdbc.pwd=deng123456
jdbc.xiaopeng2.url=jdbc:mysql://10.46.120.165:3306/xiaopeng2?user=denglh2&password=deng123456&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false
jdbc.xiaopeng2.user=denglh2
jdbc.xiaopeng2.pwd=deng123456
jdbc.xiaopeng2bihip.url=jdbc:mysql://10.46.120.165:3306/xiaopeng2?user=denglh2&password=deng123456&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false
jdbc.xiaopeng2fx.url=jdbc:mysql://10.46.120.165:3306/xiaopeng2_faxing?user=denglh2&password=deng123456&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false&zeroDateTimeBehavior=convertToNull
jdbc.xiaopeng2fx.user=denglh2
jdbc.xiaopeng2fx.pwd=deng123456
jdbc.driver=com.mysql.jdbc.Driver


# kafka 配置
kafka.metadata.broker.list=hadoopmaster:9092

kafka.topics.centurioncardaccount=login,regi,order
spark.checkpoint.centurioncardaccount=/home/hduser/spark/spark-1.6.1/checkpointdir/centurioncardaccount

kafka.topics.apppoints=order,points
spark.checkpoint.apppoints=/home/hduser/spark/spark-1.6.1/checkpointdir/apppoints

kafka.topics.kpi=regi,order,login,active,pubgame,channel,request,thirddata
spark.checkpoint.kpi=/home/hduser/spark/spark-1.6.1/checkpointdir/checkpointkpi

kafka.topics.backend=member,regi,order,binduid,login
spark.checkpoint.backend=/home/hduser/spark/spark-1.6.1/checkpointdir/backend

#kafka.topics.member=member,regi,order,binduid
#spark.checkpoint.member=/home/hduser/spark/spark-1.6.1/checkpointdir/member

kafka.topics.alliance.kpi=regi,order,login,active
spark.checkpoint.alliance.kpi=file:///home/hduser/spark/spark-1.6.1/checkpointdir/checkpointalliancekpi

#离线任务 数据目录配置
gamepublish.offline.regi=hdfs://hadoopmaster:9000/user/hive/warehouse/yyft.db/regi/*
gamepublish.offline.order=hdfs://hadoopmaster:9000/user/hive/warehouse/yyft.db/order/*
gamepublish.offline.thirddata=hdfs://hadoopmaster:9000/user/hive/warehouse/yyft.db/thirddata/*

fxdim.parquet=hdfs://hadoopmaster:9000/tmp/hive/fxdim.parquet

# spark 参数配置
coalesce.partitioin.num=40
spark.sql.shuffle.partitions=40
spark.memory.storageFraction=0.2

#redis相关配置
redis.host=10.30.3.17
redis.port=6379
redis.max.idle=50
redis.max.total=1000
redis.max.wait.millis=10000

#web交互的模式
web.url.mode=test

#kafka regi日志缓存一批目录地址
regi_log_cache=file:///home/hduser/spark/spark-1.6.1/checkpointdir/thirddata_regi_log_cache

